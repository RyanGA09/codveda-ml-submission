{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Data Preprocessing for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_DIR = \"data/raw\"\n",
    "PROCESSED_DATA_DIR = \"data/processed\"\n",
    "os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_iris():\n",
    "    df = pd.read_csv(os.path.join(RAW_DATA_DIR, \"iris.csv\"))\n",
    "    df.to_csv(os.path.join(PROCESSED_DATA_DIR, \"iris_processed.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_stock_prices():\n",
    "    df = pd.read_csv(os.path.join(RAW_DATA_DIR, \"Stock Prices Data Set.csv\"))\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df[['open', 'high', 'low', 'close', 'volume']] = df[['open', 'high', 'low', 'close', 'volume']].astype(float)\n",
    "    df.to_csv(os.path.join(PROCESSED_DATA_DIR, \"stock_prices_processed.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentiment():\n",
    "    df = pd.read_csv(os.path.join(RAW_DATA_DIR, \"Sentiment dataset.csv\"))\n",
    "    df = df.drop(columns=['Unnamed: 0'])\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "    df.to_csv(os.path.join(PROCESSED_DATA_DIR, \"sentiment_processed.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_house():\n",
    "    df = pd.read_csv(os.path.join(RAW_DATA_DIR, \"house Prediction Data Set.csv\"), delim_whitespace=True, header=None)\n",
    "    df.to_csv(os.path.join(PROCESSED_DATA_DIR, \"house_processed.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_churn(filename, output_filename):\n",
    "    df = pd.read_csv(os.path.join(RAW_DATA_DIR, filename))\n",
    "\n",
    "    # Debugging: Pastikan kolom sesuai ekspektasi\n",
    "    print(\"Kolom dalam dataset:\", df.columns.tolist())\n",
    "\n",
    "    # Bersihkan nama kolom dari spasi tersembunyi\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    categorical_features = ['State', 'International plan', 'Voice mail plan']\n",
    "    numerical_features = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "    # Pastikan 'Churn' ada sebelum drop\n",
    "    if 'Churn' in numerical_features:\n",
    "        numerical_features = numerical_features.drop('Churn')\n",
    "\n",
    "    if 'Churn' not in df.columns:\n",
    "        raise KeyError(\"Kolom 'Churn' tidak ditemukan dalam dataset!\")\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "    X = df.drop(columns=['Churn'])\n",
    "    y = df['Churn']\n",
    "\n",
    "    # Langsung transformasi tanpa split ulang\n",
    "    X_processed = preprocessor.fit_transform(X)\n",
    "\n",
    "    pd.DataFrame(X_processed).to_csv(os.path.join(PROCESSED_DATA_DIR, f\"{output_filename}_X.csv\"), index=False)\n",
    "    pd.DataFrame(y).to_csv(os.path.join(PROCESSED_DATA_DIR, f\"{output_filename}_y.csv\"), index=False)\n",
    "\n",
    "    print(f\"Preprocessing selesai untuk {filename}. File disimpan di {PROCESSED_DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ryan\\AppData\\Local\\Temp\\ipykernel_36072\\3514313085.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(RAW_DATA_DIR, \"house Prediction Data Set.csv\"), delim_whitespace=True, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kolom dalam dataset: ['State', 'Account length', 'Area code', 'International plan', 'Voice mail plan', 'Number vmail messages', 'Total day minutes', 'Total day calls', 'Total day charge', 'Total eve minutes', 'Total eve calls', 'Total eve charge', 'Total night minutes', 'Total night calls', 'Total night charge', 'Total intl minutes', 'Total intl calls', 'Total intl charge', 'Customer service calls', 'Churn']\n",
      "Preprocessing selesai untuk churn-bigml-20.csv. File disimpan di data/processed\n",
      "Kolom dalam dataset: ['State', 'Account length', 'Area code', 'International plan', 'Voice mail plan', 'Number vmail messages', 'Total day minutes', 'Total day calls', 'Total day charge', 'Total eve minutes', 'Total eve calls', 'Total eve charge', 'Total night minutes', 'Total night calls', 'Total night charge', 'Total intl minutes', 'Total intl calls', 'Total intl charge', 'Customer service calls', 'Churn']\n",
      "Preprocessing selesai untuk churn-bigml-80.csv. File disimpan di data/processed\n",
      "Preprocessing is complete. File saved in data/processed\n"
     ]
    }
   ],
   "source": [
    "preprocess_iris()\n",
    "preprocess_stock_prices()\n",
    "preprocess_sentiment()\n",
    "preprocess_house()\n",
    "preprocess_churn(\"churn-bigml-20.csv\", \"churn_20_processed\")\n",
    "preprocess_churn(\"churn-bigml-80.csv\", \"churn_80_processed\")\n",
    "\n",
    "print(\"Preprocessing is complete. File saved in data/processed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
