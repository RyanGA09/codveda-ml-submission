{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Data Preprocessing for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage directory\n",
    "RAW_DATA_DIR = \"data/raw\"\n",
    "PROCESSED_DATA_DIR = \"data/processed\"\n",
    "os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_iris():\n",
    "    df = pd.read_csv(os.path.join(RAW_DATA_DIR, \"iris.csv\"))\n",
    "\n",
    "    # Handle missing values hanya pada kolom numerik\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n",
    "\n",
    "    # Standardize numeric features\n",
    "    scaler = StandardScaler()\n",
    "    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "    # Split data\n",
    "    train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    train.to_csv(os.path.join(PROCESSED_DATA_DIR, \"iris_train.csv\"), index=False)\n",
    "    test.to_csv(os.path.join(PROCESSED_DATA_DIR, \"iris_test.csv\"), index=False)\n",
    "    print(f\"Preprocessing completed for `iris.csv`. Files saved in {PROCESSED_DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_stock_prices():\n",
    "    df = pd.read_csv(os.path.join(RAW_DATA_DIR, \"Stock Prices Data Set.csv\"))\n",
    "\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    numeric_cols = ['open', 'high', 'low', 'close', 'volume']\n",
    "    df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Handle missing values\n",
    "    df.fillna(df.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "    # Standardize numeric features\n",
    "    scaler = StandardScaler()\n",
    "    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "    # Split data\n",
    "    train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    train.to_csv(os.path.join(PROCESSED_DATA_DIR, \"stock_prices_train.csv\"), index=False)\n",
    "    test.to_csv(os.path.join(PROCESSED_DATA_DIR, \"stock_prices_test.csv\"), index=False)\n",
    "    print(f\"Preprocessing completed for `Stock Prices Data Set.csv`. Files saved in {PROCESSED_DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentiment():\n",
    "    df = pd.read_csv(os.path.join(RAW_DATA_DIR, \"Sentiment dataset.csv\"))\n",
    "    df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "\n",
    "    # Handle missing values\n",
    "    df.fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "    # Split data\n",
    "    train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    train.to_csv(os.path.join(PROCESSED_DATA_DIR, \"sentiment_train.csv\"), index=False)\n",
    "    test.to_csv(os.path.join(PROCESSED_DATA_DIR, \"sentiment_test.csv\"), index=False)\n",
    "    print(f\"Preprocessing completed for `Sentiment dataset.csv`. Files saved in {PROCESSED_DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_house():\n",
    "    df = pd.read_csv(os.path.join(RAW_DATA_DIR, \"house Prediction Data Set.csv\"), delim_whitespace=True, header=None)\n",
    "\n",
    "    # Handle missing values\n",
    "    df.fillna(df.median(), inplace=True)\n",
    "\n",
    "    # Standardize numeric features\n",
    "    scaler = StandardScaler()\n",
    "    df[df.columns] = scaler.fit_transform(df[df.columns])\n",
    "\n",
    "    # Split data\n",
    "    train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    train.to_csv(os.path.join(PROCESSED_DATA_DIR, \"house_train.csv\"), index=False)\n",
    "    test.to_csv(os.path.join(PROCESSED_DATA_DIR, \"house_test.csv\"), index=False)\n",
    "    print(f\"Preprocessing completed for `house Prediction Data Set.csv`. Files saved in {PROCESSED_DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing completed for `iris.csv`. Files saved in data/processed\n",
      "Preprocessing completed for `Stock Prices Data Set.csv`. Files saved in data/processed\n",
      "Preprocessing completed for `Sentiment dataset.csv`. Files saved in data/processed\n",
      "Preprocessing completed for `house Prediction Data Set.csv`. Files saved in data/processed\n",
      "✅ Preprocessing is complete. Files saved in data/processed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ryan\\AppData\\Local\\Temp\\ipykernel_8300\\205777424.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(RAW_DATA_DIR, \"house Prediction Data Set.csv\"), delim_whitespace=True, header=None)\n"
     ]
    }
   ],
   "source": [
    "# Code Execution\n",
    "preprocess_iris()\n",
    "preprocess_stock_prices()\n",
    "preprocess_sentiment()\n",
    "preprocess_house()\n",
    "\n",
    "print(\"✅ Preprocessing is complete. Files saved in data/processed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
