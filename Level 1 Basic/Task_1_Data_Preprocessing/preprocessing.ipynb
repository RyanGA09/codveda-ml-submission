{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Data Preprocessing for Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storage directory\n",
    "RAW_DATA_DIR = \"data/raw\"\n",
    "PROCESSED_DATA_DIR = \"data/processed\"\n",
    "os.makedirs(PROCESSED_DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_iris():\n",
    "    df = pd.read_csv(os.path.join(RAW_DATA_DIR, \"iris.csv\"))\n",
    "\n",
    "    # Handle missing values hanya pada kolom numerik\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].mean())\n",
    "\n",
    "    # Standardize numeric features\n",
    "    scaler = StandardScaler()\n",
    "    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "    # Split data\n",
    "    train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    train.to_csv(os.path.join(PROCESSED_DATA_DIR, \"iris_train.csv\"), index=False)\n",
    "    test.to_csv(os.path.join(PROCESSED_DATA_DIR, \"iris_test.csv\"), index=False)\n",
    "    print(f\"Preprocessing completed for `iris.csv`. Files saved in {PROCESSED_DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_stock_prices():\n",
    "    df = pd.read_csv(os.path.join(RAW_DATA_DIR, \"Stock Prices Data Set.csv\"))\n",
    "\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    numeric_cols = ['open', 'high', 'low', 'close', 'volume']\n",
    "    df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Handle missing values\n",
    "    df.fillna(df.mean(numeric_only=True), inplace=True)\n",
    "\n",
    "    # Standardize numeric features\n",
    "    scaler = StandardScaler()\n",
    "    df[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "    # Split data\n",
    "    train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    train.to_csv(os.path.join(PROCESSED_DATA_DIR, \"stock_prices_train.csv\"), index=False)\n",
    "    test.to_csv(os.path.join(PROCESSED_DATA_DIR, \"stock_prices_test.csv\"), index=False)\n",
    "    print(f\"Preprocessing completed for `Stock Prices Data Set.csv`. Files saved in {PROCESSED_DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentiment():\n",
    "    df = pd.read_csv(os.path.join(RAW_DATA_DIR, \"Sentiment dataset.csv\"))\n",
    "    df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "\n",
    "    # Handle missing values\n",
    "    df.fillna(\"Unknown\", inplace=True)\n",
    "\n",
    "    # Split data\n",
    "    train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    train.to_csv(os.path.join(PROCESSED_DATA_DIR, \"sentiment_train.csv\"), index=False)\n",
    "    test.to_csv(os.path.join(PROCESSED_DATA_DIR, \"sentiment_test.csv\"), index=False)\n",
    "    print(f\"Preprocessing completed for `Sentiment dataset.csv`. Files saved in {PROCESSED_DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_house():\n",
    "    df = pd.read_csv(os.path.join(RAW_DATA_DIR, \"house Prediction Data Set.csv\"), delim_whitespace=True, header=None)\n",
    "\n",
    "    # Handle missing values\n",
    "    df.fillna(df.median(), inplace=True)\n",
    "\n",
    "    # Standardize numeric features\n",
    "    scaler = StandardScaler()\n",
    "    df[df.columns] = scaler.fit_transform(df[df.columns])\n",
    "\n",
    "    # Split data\n",
    "    train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "    train.to_csv(os.path.join(PROCESSED_DATA_DIR, \"house_train.csv\"), index=False)\n",
    "    test.to_csv(os.path.join(PROCESSED_DATA_DIR, \"house_test.csv\"), index=False)\n",
    "    print(f\"Preprocessing completed for `house Prediction Data Set.csv`. Files saved in {PROCESSED_DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_churn(filename, output_filename):\n",
    "    df = pd.read_csv(os.path.join(RAW_DATA_DIR, filename))\n",
    "\n",
    "    # Debugging: Ensure columns are as expected\n",
    "    print(\"Columns in the dataset:\", df.columns.tolist())\n",
    "\n",
    "    # Handle missing values only in numerical columns\n",
    "    df.fillna(df.select_dtypes(include=['int64', 'float64']).median(), inplace=True)\n",
    "\n",
    "    # Clear column names from hidden spaces\n",
    "    df.columns = df.columns.str.strip()\n",
    "\n",
    "    categorical_features = ['State', 'International plan', 'Voice mail plan']\n",
    "    numerical_features = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "    # Ensure 'Churn' exists before dropping\n",
    "    if 'Churn' in numerical_features:\n",
    "        numerical_features.remove('Churn')\n",
    "\n",
    "    if 'Churn' not in df.columns:\n",
    "        raise KeyError(\"The column 'Churn' is not found in the dataset!\")\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('num', StandardScaler(), numerical_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "    ])\n",
    "\n",
    "    X = df.drop(columns=['Churn'])\n",
    "    y = df['Churn']\n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Apply transformations\n",
    "    X_train_processed = preprocessor.fit_transform(X_train)\n",
    "    X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "    # Save processed data\n",
    "    pd.DataFrame(X_train_processed).to_csv(os.path.join(PROCESSED_DATA_DIR, f\"{output_filename}_X_train.csv\"), index=False)\n",
    "    pd.DataFrame(X_test_processed).to_csv(os.path.join(PROCESSED_DATA_DIR, f\"{output_filename}_X_test.csv\"), index=False)\n",
    "    pd.DataFrame(y_train).to_csv(os.path.join(PROCESSED_DATA_DIR, f\"{output_filename}_y_train.csv\"), index=False)\n",
    "    pd.DataFrame(y_test).to_csv(os.path.join(PROCESSED_DATA_DIR, f\"{output_filename}_y_test.csv\"), index=False)\n",
    "\n",
    "    print(f\"Preprocessing completed for {filename}. Files saved in {PROCESSED_DATA_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing completed for `iris.csv`. Files saved in data/processed\n",
      "Preprocessing completed for `Stock Prices Data Set.csv`. Files saved in data/processed\n",
      "Preprocessing completed for `Sentiment dataset.csv`. Files saved in data/processed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ryan\\AppData\\Local\\Temp\\ipykernel_26408\\205777424.py:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
      "  df = pd.read_csv(os.path.join(RAW_DATA_DIR, \"house Prediction Data Set.csv\"), delim_whitespace=True, header=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing completed for `house Prediction Data Set.csv`. Files saved in data/processed\n",
      "Columns in the dataset: ['State', 'Account length', 'Area code', 'International plan', 'Voice mail plan', 'Number vmail messages', 'Total day minutes', 'Total day calls', 'Total day charge', 'Total eve minutes', 'Total eve calls', 'Total eve charge', 'Total night minutes', 'Total night calls', 'Total night charge', 'Total intl minutes', 'Total intl calls', 'Total intl charge', 'Customer service calls', 'Churn']\n",
      "Preprocessing completed for churn-bigml-20.csv. Files saved in data/processed\n",
      "Columns in the dataset: ['State', 'Account length', 'Area code', 'International plan', 'Voice mail plan', 'Number vmail messages', 'Total day minutes', 'Total day calls', 'Total day charge', 'Total eve minutes', 'Total eve calls', 'Total eve charge', 'Total night minutes', 'Total night calls', 'Total night charge', 'Total intl minutes', 'Total intl calls', 'Total intl charge', 'Customer service calls', 'Churn']\n",
      "Preprocessing completed for churn-bigml-80.csv. Files saved in data/processed\n",
      "âœ… Preprocessing is complete. Files saved in data/processed.\n"
     ]
    }
   ],
   "source": [
    "# Code Execution\n",
    "preprocess_iris()\n",
    "preprocess_stock_prices()\n",
    "preprocess_sentiment()\n",
    "preprocess_house()\n",
    "preprocess_churn(\"churn-bigml-20.csv\", \"churn_20_processed\")\n",
    "preprocess_churn(\"churn-bigml-80.csv\", \"churn_80_processed\")\n",
    "\n",
    "print(\"âœ… Preprocessing is complete. Files saved in data/processed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
